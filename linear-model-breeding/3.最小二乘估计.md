> [!NOTE]
>
> ==最小二乘适用于估计固定效应值==



# 一、常规最小二乘估计（OLS）

## 1.最小二乘方程组

通常的多元线性回归模型可看作是一种固定模型，具有只其中的 $\beta$为偏回归系数的向量，$\mathbf{X}$为已知的常数矩阵。我们考虑：
$$
Q = e'e = (y - \mathbf{X}\beta)'(y - \mathbf{X}\beta)
$$
**最小二乘方程组**：
$$
\mathbf{X}'\mathbf{X}\hat{\beta} = \mathbf{X}'y
$$


## 2.最小二乘方程组的求解

### &#9312;系数矩阵($\mathbf{X}'\mathbf{X}$)非满秩

#### &#9332;广义求解法

$$
\beta^{0} =(\mathbf{X}'\mathbf{X})^{-} \mathbf{X}'y
$$



分快矩阵求逆法:

* $\mathbf{A}=\begin{bmatrix}\mathbf{A}_{11} & \mathbf{A}_{12} \\\mathbf{A}_{21}& \mathbf{A}_{22}\end{bmatrix}$其中$\mathbf{A}_{11}$和$\mathbf{A}_{22}$均可逆，则$\mathbf{A}^{-1}=\begin{bmatrix}\mathbf{C}_{11} & \mathbf{C}_{12} \\\mathbf{C}_{21}& \mathbf{C}_{22}\end{bmatrix}$通过$\mathbf{A}\mathbf{A}^{-1}=I$求解
* $\mathbf{A}$是$\mathbf{X}'\mathbf{X}$经过初等变换后得到的分快矩阵，其为满秩（等于$\mathbf{X}'\mathbf{X}$的秩）

#### &#9333;引入拉格朗日乘子求解

> [!NOTE]
>
> 引入约束条件$\mathbf{H}\hat{\beta}=0$

加入约束条件后的方程组：
$$
\left[
\begin{array}{cc}
X'X & H' \\
H & 0
\end{array}
\right]
\left[
\begin{array}{c}
\hat{\beta} \\
\theta
\end{array}
\right]
=
\left[
\begin{array}{c}
X'y \\
0
\end{array}
\right]
$$
其中$\mathbf{H}$是根据根据因子水平设定的

例如，矩阵 \( H \) 的构造如下：$
H = \begin{bmatrix}
0 & 1 & 1 & 0 & 0 & 0  \\
0 & 0 & 0 & 1 & 1 & 1 
\end{bmatrix}
$

这表示有两个约束条件：$\begin{cases}
\alpha_1 + \alpha_2 = 0 \\
\beta_1 + \beta_2 + \beta_3  = 0
\end{cases}$



#### &#9334;引入和约束条件求解

$$
\left[
\begin{array}{cc}
X'X \\ H
\end{array}
\right]
\hat{\beta} 
=
\left[
\begin{array}{c}
X'y \\
0
\end{array}
\right]
$$

其中$\mathbf{H}$是根据根据因子水平的关系设定的

解法：由于列之间存在线性关系，删除相关行的因子后求解。其中$\mathbf{X}_{r}$为消去相应列（既相关因子）后的结构矩阵.
$$
\hat{\beta} 
=\left[
\begin{array}{cc}
X'_{r}X \\ H
\end{array}
\right]^{-1}
\left[
\begin{array}{c}
X'_{r}\\
0
\end{array}
\right]y=\mathbf{T}\mathbf{y}
$$

#### &#9335;Harvey线性约束下求解

$\begin{cases}
\alpha_1 + \alpha_2 = 0 \\
\beta_1 + \beta_2 + \beta_3  = 0\end{cases}$进行变换$\begin{cases}
 \alpha_2 =- \alpha_1 \\
 \beta_3  =-\beta_1 -\beta_2 \end{cases}$

然后将最后一列乘以$-1$分别加到倒数第二列与倒数第三列并将最后一列删除；同理操作得到$\mathbf{X}_{r}$得最小二乘估计方程：
$$
\mathbf{X}_{r}^{T}\mathbf{X}_{r}\hat{\beta}_{r}=\mathbf{X}_{r}^{T}\mathbf{y}
$$

#### &#9336;再参数化求解

**再参数化求解步骤总结**：

1. **确定原模型的问题**  

- 检查设计矩阵$ \mathbf{X}$的列秩$ t$。若 $\mathbf{X}$ 列不满秩（即存在多重共线性），原参数 $\beta $无法唯一估计。

2. **构造新参数 $r$**

- 定义线性无关且可估计的新参数 $r =\mathbf{K} '\beta$，其中 $\mathbf{K}$是 $(p \times t) $矩阵$p$为原参数维度，$t$为 $\mathbf{X}$的秩。

$$
\mathbf{r} = 
\begin{bmatrix}
1 & 1 & 0 & 1 & 0 & 0 \\
0 & 0 & 0 & -1 & 1 & 0 \\
0 & 0 & 0 & -1 & 0 & 1 \\
0 & -1 & 1 & 0 & 0 & 0
\end{bmatrix}
\boldsymbol{\beta} = \mathbf{K}'\boldsymbol{\beta}
$$

  

- $\mathbf{K}$ 的列需满足 $\mathbf{K}'\beta$ 为可估计函数，且彼此线性无关（即 $\mathbf{K}'\mathbf{K}$ 满秩）。

> [!NOTE]
>
> ==重新定义参数的原则==
>
> 1. **可估计性原则**：新参数必须为原参数的可估计函数，即能通过观测数据唯一确定。
>
> 	&#9312;**对比**：定义参数为处理效应间的差异如  $r_2 = \beta_2 - \beta_1 $
> 	&#9313;**基准组合**：选取基准水平，其他参数定义为相对于基准的偏移如 $ r_1 = \mu + \alpha_1 + \beta_1$ 作为基准
>
> 2. **线性无关性要求**
> 	&#9312;新参数需彼此线性无关，确保新设计矩阵 $\mathbf{X}_r$  列满秩。例如：$ r_1 = \mu + \alpha_1 $和$r_2 = \mu + \alpha_2 $，则 $ r_1 - r_2 = \alpha_1 - \alpha_2$  隐含冗余，需避免。
>
> 3. **信息等价性**
>
> 	&#9312;新参数系统需与原模型等价，即 $ \mathbf{X}_r \mathbf{r} = \mathbf{X} \boldsymbol{\beta} $通过合理定义参数，保留所有可估计的信息。例如：在方差分析中，定义 $r_1 = \mu + \alpha_1 + \beta_1$ 和对比项 $ r_2 = \beta_2 - \beta_1$ 可完整描述处理效应。
>
> 4. **参数化方法的选择灵活性**
> 	在满足上述原理的前提下，参数定义可根据研究需求灵活选择：
> 	&#9312;**对比类型**：如 Treatment Contrasts（以某一水平为基准）、Sum Contrasts（参数之和为0）、Helmert Contrasts（逐级比较）。
> 	&#9313;**基准调整**：选择不同的基准水平如 $ \beta_1 $ 或  $\beta_2$影响参数解释，但不影响模型拟合。

$$
\mathbf{r} = 
\begin{bmatrix}
1 & 1 & 0 & 1 & 0 & 0 \\
0 & 0 & 0 & -1 & 1 & 0 \\
0 & 0 & 0 & -1 & 0 & 1 \\
0 & -1 & 1 & 0 & 0 & 0
\end{bmatrix}
\boldsymbol{\beta} = \mathbf{K}'\boldsymbol{\beta}
$$

3. **构建新模型**  

- 将原模型 $\mathbf{y} = \mathbf{X}\beta + e$转化为 $\mathbf{y} =\mathbf{X}_{r}\mathbf{r}  + e$，其中 $\mathbf{X}_r = \mathbf{X}\mathbf{K}(\mathbf{X}^{T}\mathbf{K})^{-1}$。  
- 新关联矩阵 $\mathbf{X}_r$列满秩，确保最小二乘方程组可解。

4. **求解新模型的最小二乘估计**  

- 通过列满秩方程组$ (\mathbf{X}_r'\mathbf{X}_r)\hat{r} = \mathbf{X}_r'\mathbf{y}) $求解 $\hat{r}$。

## 3.最小二乘估计量的标准误与相关系数

设 $\hat{\beta} = \mathbf{T} y$，它的方差协方差矩阵为：

$$
\mathbf{V}_{\hat{\beta}} = \mathbf{T} \mathbf{V}_y \mathbf{T}' = \mathbf{T} \sigma^2 \mathbf{I} \mathbf{T}' = \mathbf{T} \mathbf{T}' \sigma^2
$$
一般情况下残差方差 $\sigma^2$是未知的，我们可根据以下公式估计：

$$
\hat{\sigma}^2 = \frac{y'y - \hat{\beta}'X'y}{N - r}
$$
其中：
- N：观测值个数  
- $\mathbf{r}=\mathbf{X}$矩阵中线性无关的列数（即模型的秩）

### &#9312;估计值的标准误

$\mathbf{V}_{\hat{\beta}}$中对角线元素为$\beta$的估计值的**方差**，非对角线为估计值的协方差。

### &#9313;$\hat{\beta}$各元素间的相关系数：

$$
\mathbf{R}_{\hat{\beta}}=\mathbf{S}_{\hat{\beta}}^{-1}\mathbf{V}_{\hat{\beta}}\mathbf{S}_{\hat{\beta}}^{-1}
$$



# 二、广义最小二乘估计（GLS)

> [!NOTE]
>
> ==随机误差间并非相互独立==

## 1.**广义最小二乘方程组**

$$
\mathbf{X}^{\prime} \mathbf{R}^{-1} \mathbf{X }\tilde{\beta} =\mathbf{X}^{\prime} \mathbf{R}^{-1} \mathbf{y}
$$

### &#9312;当$\mathbf{X}^{\prime} \mathbf{R}^{-1} \mathbf{X }$非满秩时

不管哪种模型，只要$E(\mathbf{y})=\mathbf{X}\beta$,$Var(\mathbf{y})=V$
$$
\mathbf{X}^{\prime} \mathbf{V}^{-1} \mathbf{X} \tilde{\beta} = \mathbf{X}^{\prime} \mathbf{V}^{-1}\mathbf{y}
$$
其中：$\hat{\beta} =(\mathbf{X}^{\prime} \mathbf{V}^{-1} \mathbf{X })^{-}\mathbf{X}^{\prime} \mathbf{V}^{-1} \mathbf{y}$

## 2.性质

&#9312;不满秩，若$\mathbf{K}^{\prime}\beta$为可估计函数，$\mathbf{X}^{\prime} \mathbf{V}^{-1} \mathbf{X}$可能存在多个广元逆，$\mathbf{K}^{\prime}\tilde\beta$是唯一的，且为$\mathbf{K}^{\prime}\beta$最佳线性无偏线性估计

&#9313;$\mathbb{E}(\hat{\beta}) = (\mathbf{X}' \mathbf{V}^{-1} \mathbf{X})^{-1} \mathbf{X}' \mathbf{V}^{-1} \mathbf{X} \beta
$

&#9314;$\mathbf{K}^{\prime}\tilde\beta$的方差：$\text{Var}(K' \beta) = K' (X' V^{-1} X)^{-1} K$

## 3.求解

$$
\mathbf{V}_y = \text{Var}(Zu) + \text{Var}(e) = Z \mathbf{V}_u Z' + \mathbf{V}_e
\mathbf{V}_y^{-1} = \mathbf{R}^{-1} - \mathbf{R}^{-1} \mathbf{Z} (\mathbf{Z}' \mathbf{R}^{-1} \mathbf{Z} + \mathbf{G}^{-1})^{-1} \mathbf{Z}' \mathbf{R}^{-1}
$$

**不满秩时，引入和约束条件，抛弃$\tilde\mu$引入$\mathbf{H}$矩阵。**

