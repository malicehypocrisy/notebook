# 一、线性模型的一般形式

$$
\begin{array}{l}
\mathbf{y} = \mathbf{X b} + \mathbf{Z u} + \mathbf{e} \\
\mathbf{y} \text{：观测值向量} \\
\mathbf{b} \text{：固定效应向量（可包含总平均，可以有多个固定因子）} \\
\mathbf{X} \text{：} \mathbf{b} \text{的关联矩阵} \\
\mathbf{u} \text{：随机效应向量（可以有多个随机因子）} \\
\mathbf{Z} \text{：} \mathbf{u} \text{的关联矩阵} \\
\mathbf{e} \text{：残差效应向量}
E(\mathbf{u})=\mathbf{0} \quad E(\mathbf{e})=\mathbf{0} \quad E(\mathbf{y})=\mathbf{X} \mathbf{b} \\
\operatorname{Var}(\mathbf{u})=\mathbf{G} \quad \operatorname{Var}(\mathbf{e})=\mathbf{R} \quad \operatorname{Cov}\left(\mathbf{u}, \mathbf{e}^{\prime}\right)=\mathbf{0} \\
\operatorname{Var}(\mathbf{y})=\mathbf{V}=\operatorname{Var}(\mathbf{Z u}+\mathbf{e})=\operatorname{Var}(\mathbf{Z u})+\operatorname{Var}(\mathbf{e})=\mathbf{Z} \operatorname{Var}(\mathbf{u}) \mathbf{Z}^{\prime}+\mathbf{R}=\mathbf{Z} \mathbf{G } \mathbf{Z}^{\prime}+\mathbf{R} \\
\operatorname{Cov}\left(\mathbf{y}, \mathbf{u}^{\prime}\right)=\operatorname{Cov}\left(\mathbf{Z u}+\mathbf{e}, \mathbf{u}^{\prime}\right)=\operatorname{Cov}\left(\mathbf{Z u}, \mathbf{u}^{\prime}\right)+\operatorname{Cov}\left(\mathbf{e}, \mathbf{u}^{\prime}\right)=\mathbf{Z} \mathbf{G} \\
\operatorname{Cov}\left(\mathbf{y}, \mathbf{e}^{\prime}\right)=\mathbf{R}
\end{array}
$$

# 二、常规最小二乘估计（OLS）

## &#9352;最小二乘方程组

* 将多元线性回归模型可看作是一种**固定模型**

$$
Q = e'e = (y - \mathbf{X}\beta)'(y - \mathbf{X}\beta)\rightarrow\mathbf{X}'\mathbf{X}\hat{\beta} = \mathbf{X}'y\\
\text{系数矩阵满秩：}\beta^{0} =(\mathbf{X}'\mathbf{X})^{-} \mathbf{X}'y
$$
## &#9353;广义逆求解法

### &#9312;分块矩阵求逆法

* $\mathbf{A}=\begin{bmatrix}\mathbf{A}_{11} & \mathbf{A}_{12} \\\mathbf{A}_{21}& \mathbf{A}_{22}\end{bmatrix}$其中$\mathbf{A}_{11}$和$\mathbf{A}_{22}$均可逆，则$\mathbf{A}^{-1}=\begin{bmatrix}\mathbf{C}_{11} & \mathbf{C}_{12} \\\mathbf{C}_{21}& \mathbf{C}_{22}\end{bmatrix}$通过$\mathbf{A}\mathbf{A}^{-1}=I$求解
* $\mathbf{A}$是$\mathbf{X}'\mathbf{X}$**经过初等变换后得到的分块矩阵**，其为满秩（等于$\mathbf{X}'\mathbf{X}$的秩）

### &#9313;引入拉格朗日乘子求解

* 引入约束条件：

$$
\mathbf{H}\hat{\beta}=0
$$

* 在约束条件下，**方程组有唯一解的必要条件**

$$
r\left[
\begin{array}{cc}
X\\H 
\end{array}
\right]
=p&p=\mathbf{X}\text{的列数}
$$

* 加入约束条件后的方程组：

$$
\left[
\begin{array}{cc}
X'X & H' \\
H & 0
\end{array}
\right]
\left[
\begin{array}{c}
\hat{\beta} \\
\theta
\end{array}
\right]
=
\left[
\begin{array}{c}
X'y \\
0
\end{array}
\right]
 \\\text{其中，}\theta\text{拉格朗日乘子；}\mathbf{H}\text{是根据根据因子水平设定的}
$$
### &#9314;引入和约束条件求解

$$
\left[
\begin{array}{cc}
X'X \\ H
\end{array}
\right]
\hat{\beta} 
=
\left[
\begin{array}{c}
X'y \\
0
\end{array}
\right]
\text{其中，}\mathbf{H}\text{是根据根据因子水平设定的}
$$

#### &#9332;解法

* 删除某些行，避免存在线性相关的方程。

$$
\hat{\beta} 
=\left[
\begin{array}{cc}
X'_{r}X \\ H
\end{array}
\right]^{-1}
\left[
\begin{array}{c}
X'_{r}\\
0
\end{array}
\right]y=\mathbf{T}\mathbf{y}
$$

* 其中$\mathbf{X}_{r}$为**删掉相应列**后的结构矩阵.

### &#9315;Harvey线性约束下求解

* 通过因子之间关系变化合并掉相关列，让结构矩阵变成列满秩矩阵

$$
\mathbf{X}_{r}^{T}\mathbf{X}_{r}\hat{\beta}_{r}=\mathbf{X}_{r}^{T}\mathbf{y}
$$

### &#9316;再参数化求解

* 对问题设计的未知参数进行重新定义，重新定义的参数是**原参数的可估计函数**。
* 设$\beta$为原未知参数向量，与$\beta$对应的关联矩阵$\mathbf{X}$的列秩为$t$，则定义为$\mathbf{r=K^`\beta}$，其阶数为$t$，彼此线性无关，其模型为

$$
\mathbf{y=X_r r+e}
\\\text{其中，}\mathbf{X_r}\text{为与}\mathbf{r}\text{对应的}(n\times t)\text{阶关联矩阵，它的列是满秩的}
\\\mathbf{X_r=XK(K^`K)^{-1}}
$$

## &#9354;最小二乘估计量的标准误与相关系数

* 设 $\hat{\beta} = \mathbf{T} y$，其方差协方差矩阵：

$$
\mathbf{V}_{\hat{\beta}} = \mathbf{T} \mathbf{V}_y \mathbf{T}' = \mathbf{T} \sigma^2 \mathbf{I} \mathbf{T}' = \mathbf{T} \mathbf{T}' \sigma^2
$$
* 残差方差 $\sigma^2$的估计公式：

$$
\hat{\sigma}^2 = \frac{y'y - \hat{\beta}'X'y}{N - r}
$$
- N：观测值个数  
- $\mathbf{r}=\mathbf{X}$矩阵中线性无关的列数（即模型的秩）

### &#9312;估计值的标准误

* $\mathbf{V}_{\hat{\beta}}$中对角线元素为$\beta$的估计值的**方差**。
* 非对角线是估计值的**协方差**。

### &#9313;$\hat{\beta}$各元素间的相关系数：

$$
\mathbf{R}_{\hat{\beta}}=\mathbf{S}_{\hat{\beta}}^{-1}\mathbf{V}_{\hat{\beta}}\mathbf{S}_{\hat{\beta}}^{-1}
$$



# 三、广义最小二乘估计（GLS)

* 随机误差间非相互独立

## &#9352;**广义最小二乘方程组**

$$
\mathbf{X}^{\prime} \mathbf{R}^{-1} \mathbf{X }\tilde{\beta} =\mathbf{X}^{\prime} \mathbf{R}^{-1} \mathbf{y}
$$

### &#9312;当$\mathbf{X}^{\prime} \mathbf{R}^{-1} \mathbf{X }$非满秩时

* 不管哪种模型，只要$E(\mathbf{y})=\mathbf{X}\beta$,$Var(\mathbf{y})=V$

$$
\mathbf{X}^{\prime} \mathbf{V}^{-1} \mathbf{X} \tilde{\beta} = \mathbf{X}^{\prime} \mathbf{V}^{-1}\mathbf{y}
$$
* 其中：$\hat{\beta} =(\mathbf{X}^{\prime} \mathbf{V}^{-1} \mathbf{X })^{-}\mathbf{X}^{\prime} \mathbf{V}^{-1} \mathbf{y}$

## 2.性质

&#9312;不满秩，若$\mathbf{K}^{\prime}\beta$为可估计函数，$\mathbf{X}^{\prime} \mathbf{V}^{-1} \mathbf{X}$可能存在多个广元逆，$\mathbf{K}^{\prime}\tilde\beta$是唯一的，且为$\mathbf{K}^{\prime}\beta$最佳线性无偏线性估计

&#9313;$\mathbb{E}(\hat{\beta}) = (\mathbf{X}' \mathbf{V}^{-1} \mathbf{X})^{-1} \mathbf{X}' \mathbf{V}^{-1} \mathbf{X} \beta
$

&#9314;$\mathbf{K}^{\prime}\tilde\beta$的方差：$\text{Var}(K' \beta) = K' (X' V^{-1} X)^{-1} K$

## 3.模型求逆

$$
\mathbf{V}_y = \text{Var}(Zu) + \text{Var}(e) = Z \mathbf{V}_u Z' + \mathbf{V}_e
\\\mathbf{V}_y^{-1} = \mathbf{R}^{-1} - \mathbf{R}^{-1} \mathbf{Z} (\mathbf{Z}' \mathbf{R}^{-1} \mathbf{Z} + \mathbf{G}^{-1})^{-1} \mathbf{Z}' \mathbf{R}^{-1}
$$



